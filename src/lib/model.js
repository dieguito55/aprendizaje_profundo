import * as tf from '@tensorflow/tfjs';
import { LABELS } from './labels';

export async function loadModel() {
  try {
    const model = await tf.loadLayersModel('/models/v1.0/model.json');
    console.log('‚úÖ Modelo cargado exitosamente');
    return model;
  } catch (error) {
    console.error('‚ùå Error cargando modelo:', error);
    try {
      const model = await tf.loadLayersModel('/model.json');
      console.log('‚úÖ Modelo cargado desde fallback');
      return model;
    } catch (fallbackError) {
      console.error('‚ùå Fallback tambi√©n fall√≥:', fallbackError);
      throw new Error('No se pudo cargar el modelo en ninguna ubicaci√≥n');
    }
  }
}

export function preprocess(imgEl) {
  return tf.tidy(() => {
    let tensor = tf.browser.fromPixels(imgEl)
      .resizeBilinear([224, 224])
      .toFloat();
    
    tensor = tensor.div(255.0);
    tensor = tensor.expandDims(0);
    
    return tensor;
  });
}

export function topK(probs, k = 5) {
  const values = Array.isArray(probs) ? probs : 
                probs.dataSync ? probs.dataSync() : 
                Array.from(probs);
  
  const indexedProbs = values.map((prob, index) => ({ 
    index, 
    prob,
    diseaseName: LABELS[index] || `Enfermedad ${index}`
  }));
  
  const sorted = indexedProbs.sort((a, b) => b.prob - a.prob);
  return sorted.slice(0, k);
}

// Funci√≥n mejorada SIN tidy() para evitar el warning
export async function processPrediction(predictionTensor, k = 3) {
  try {
    // Aplicar softmax si es necesario
    let probabilities = predictionTensor;
    if (predictionTensor.softmax && typeof predictionTensor.softmax === 'function') {
      probabilities = predictionTensor.softmax();
    }
    
    // Obtener los datos como array - SIN tidy ya que es async
    const probsArray = await probabilities.data();
    
    // Usar topK con el array
    const results = topK(probsArray, k);
    
    // Limpiar tensores manualmente
    if (probabilities !== predictionTensor) {
      probabilities.dispose();
    }
    
    return results;
  } catch (error) {
    console.error('Error procesando predicci√≥n:', error);
    
    // Limpiar tensores en caso de error
    if (predictionTensor && predictionTensor.dispose) {
      predictionTensor.dispose();
    }
    
    return [];
  }
}

// Funci√≥n completa de predicci√≥n que maneja todo el proceso
export async function predictComplete(model, imageElement, k = 3) {
  let tensor = null;
  let prediction = null;
  
  try {
    // 1. Preprocesar (esto usa tidy internamente)
    tensor = preprocess(imageElement);
    console.log('‚úÖ Tensor preprocesado:', tensor.shape);
    
    // 2. Realizar predicci√≥n
    prediction = model.predict(tensor);
    console.log('‚úÖ Predicci√≥n realizada:', prediction.shape);
    
    // 3. Procesar resultados
    const results = await processPrediction(prediction, k);
    console.log('‚úÖ Resultados obtenidos:', results.length, 'predicciones');
    
    return results;
    
  } finally {
    // 4. Limpiar tensores (IMPORTANTE para evitar memory leaks)
    if (tensor) {
      tensor.dispose();
      console.log('üßπ Tensor de entrada liberado');
    }
    if (prediction) {
      prediction.dispose();
      console.log('üßπ Tensor de predicci√≥n liberado');
    }
  }
}

// Funci√≥n utilitaria para limpiar memoria
export function cleanup() {
  tf.disposeVariables();
  console.log('üßπ Memoria de TensorFlow limpiada');
}