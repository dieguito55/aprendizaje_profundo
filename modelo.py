# ==========================================================
# üî¨ Entrenamiento de un modelo Deep Learning (MobileNetV2)
# Proyecto: Clasificaci√≥n de enfermedades de la piel
# Integrantes:
#Aquino Sandoval Kenya Xiomara 
#Aracayo Mamani Jhon Marco 
#Canaza Paucara Juan Diego 
#Castro Callo Vanesa Yhoselin 
#holaa
# ==========================================================

import os
import tensorflow as tf
from tensorflow.keras import layers, models

# ==========================================================
# üß© 1Ô∏è‚É£ CONFIGURACI√ìN INICIAL
# ==========================================================

# Ruta base del dataset
base_dir = "dataset_skin"

# Par√°metros de imagen y entrenamiento
img_size = (224, 224)       # Tama√±o de entrada compatible con MobileNetV2
batch_size = 128            # N√∫mero de im√°genes por lote
epochs = 50                 # N√∫mero de iteraciones completas sobre el dataset

# ==========================================================
# ‚öôÔ∏è 2Ô∏è‚É£ CONFIGURACI√ìN DE HARDWARE (GPU RTX 4070)
# ==========================================================

print("\nüîç Verificando GPUs disponibles...")
gpus = tf.config.list_physical_devices("GPU")
print("üì¶ Dispositivos detectados:", gpus)

if gpus:
    try:
        # Se fuerza a TensorFlow a usar solo la GPU NVIDIA RTX 4070 (√≠ndice 0)
        tf.config.set_visible_devices(gpus[0], "GPU")
        tf.config.experimental.set_memory_growth(gpus[0], True)
        print(f"‚úÖ GPU activa: {gpus[0].name}")
    except Exception as e:
        print("‚ö†Ô∏è Error al configurar GPU:", e)
else:
    print("‚ùå No se detect√≥ GPU, se entrenar√° en CPU.")

# Desactivar optimizaciones de oneDNN para reducir carga en CPU
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

# ==========================================================
# üìÇ 3Ô∏è‚É£ CARGA Y PREPROCESAMIENTO DEL DATASET
# ==========================================================

print("\nüìÇ Cargando dataset dermatol√≥gico...")

# Divisi√≥n autom√°tica del dataset (80% entrenamiento, 20% validaci√≥n)
train_raw = tf.keras.utils.image_dataset_from_directory(
    base_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

val_raw = tf.keras.utils.image_dataset_from_directory(
    base_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

# Guardamos las clases detectadas
class_names = train_raw.class_names
print("üß© Clases detectadas:", class_names)

# Normalizaci√≥n de p√≠xeles y pipeline optimizado (usa CPU + GPU en paralelo)
train_ds = (
    train_raw.map(lambda x, y: (x / 255.0, y))
    .cache()
    .prefetch(tf.data.AUTOTUNE)
)

val_ds = (
    val_raw.map(lambda x, y: (x / 255.0, y))
    .cache()
    .prefetch(tf.data.AUTOTUNE)
)

# ==========================================================
# üß† 4Ô∏è‚É£ CONSTRUCCI√ìN DEL MODELO CON TRANSFER LEARNING
# ==========================================================

print("\nüß† Construyendo modelo MobileNetV2 (Transfer Learning)...")

# Cargamos MobileNetV2 preentrenado en ImageNet
base_model = tf.keras.applications.MobileNetV2(
    input_shape=img_size + (3,),
    include_top=False,       # Quitamos la capa final de clasificaci√≥n de ImageNet
    weights="imagenet"       # Usamos pesos preentrenados
)

# Congelamos las capas convolucionales base (no se reentrenan)
base_model.trainable = False

# A√±adimos nuevas capas densas (clasificador espec√≠fico dermatol√≥gico)
model = models.Sequential([
    base_model,                                 # Red convolucional base
    layers.GlobalAveragePooling2D(),            # Reduce dimensionalidad
    layers.Dense(256, activation="relu"),       # Capa oculta
    layers.Dropout(0.3),                        # Regularizaci√≥n
    layers.Dense(len(class_names), activation="softmax")  # Capa de salida
])

# Compilaci√≥n del modelo con hiperpar√°metros √≥ptimos
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

print("\n‚úÖ Modelo compilado correctamente.")
print("üßæ Arquitectura del modelo:")
model.summary()

# ==========================================================
# üßÆ 5Ô∏è‚É£ CALLBACKS (Control Inteligente del Entrenamiento)
# ==========================================================

callbacks = [
    # Detiene el entrenamiento cuando la precisi√≥n de validaci√≥n deja de mejorar
    tf.keras.callbacks.EarlyStopping(
        monitor="val_accuracy",
        patience=5,
        restore_best_weights=True
    ),
    # Guarda autom√°ticamente el mejor modelo encontrado
    tf.keras.callbacks.ModelCheckpoint(
        "modelo_piel_best.h5",
        save_best_only=True,
        monitor="val_accuracy"
    )
]

# ==========================================================
# üöÄ 6Ô∏è‚É£ ENTRENAMIENTO EN GPU RTX 4070 (DirectML)
# ==========================================================

print("\nüöÄ Entrenando modelo en GPU RTX 4070 (DirectML)...\n")

with tf.device("/device:DML:0"):  # Ejecutar expl√≠citamente en GPU DirectML
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=epochs,
        callbacks=callbacks,
        verbose=1
    )

# ==========================================================
# üíæ 7Ô∏è‚É£ GUARDADO Y VERIFICACI√ìN FINAL
# ==========================================================

# Guardar modelo final (el m√°s preciso tras validaci√≥n)
model.save("modelo_piel_final.h5")
print("\n‚úÖ Entrenamiento completado. Modelo guardado como 'modelo_piel_final.h5'")

# Confirmar GPU activa
print("\nüí™ GPU usada durante el entrenamiento:")
print(tf.config.list_logical_devices("GPU"))

# ==========================================================
# üìä 8Ô∏è‚É£ EVALUACI√ìN FINAL (Opcional)
# ==========================================================
# Puedes activar este bloque para evaluar la precisi√≥n final en validaci√≥n
"""
loss, acc = model.evaluate(val_ds)
print(f"\nüìà Precisi√≥n final del modelo: {acc*100:.2f}%")
print(f"üìâ P√©rdida final: {loss:.4f}")
"""
